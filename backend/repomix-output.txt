This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-02-02T08:10:09.006Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
backend/
  .gitignore
  app.py
  Procfile
  runtime.txt
frontend/
  app/
    globals.css
    layout.js
    page.js
    page.module.css
  components/
    views/
      end.jsx
      home.jsx
      start.jsx
      Timer.jsx
  store/
    exampleSlice.js
    store.js
    storeProvider.js
  styles/
    end.css
    home.module.css
    start.css
    timer.module.css
  .eslintrc.json
  .gitignore
  jsconfig.json
  next.config.mjs
  package.json
  README.md
model/
  css_dataset/
    reference_styles.css
    variant_styles_1.css
  legacy/
    host_images.py
    training_data.py
  .gitignore
  generate_data.py
  siamese_app.py
  test_model.py
  train_siamese.ipynb
  train.py
.babelrc
README.md

================================================================
Repository Files
================================================================

================
File: backend/.gitignore
================
.venv
__pycache__
.env
.venvlinux
static

================
File: backend/app.py
================
import os
import random
from threading import Thread
import time
import json
from uuid import uuid4
from flask import Flask, abort, make_response, request, send_from_directory
import imgkit
import requests
from dotenv import load_dotenv
from flask_cors import CORS, cross_origin
from bson.binary import Binary
from pymongo import MongoClient

load_dotenv()

THEMES = [
    "modern",
    "clean",
    "zen",
    "retro",
    "playful",
    "grand",
]
COMPONENTS = [
    # "checkbox",
    "circular button",
    "button",
    "div",
    # "progress bar",
    # "slider",
    "switch",
]

# access your database and collection from Atlas
# database = mongo_client.get_database(“anaiyamovies”)
# collection = database.get_collection(“movies”)

app = Flask(__name__)
cors = CORS(app)
BREADBOARD_URL = "https://breadboard-community.wl.r.appspot.com/boards/@ArtisticJellyfish/cascade-generator.bgl.api/run"
GRADING_URL = "https://8949-146-152-233-45.ngrok-free.app/"


def render_html(html: str):
    return imgkit.from_string(
        html,
        False,
        options={
            "crop-h": "400",
            "crop-w": "400",
            "--height": "400",
            "--width": "400",
        },
    )


def init_mongo_client(app: Flask):
    try:
        mongo_client = MongoClient(os.getenv("MONGO-CONNECTION-STRING"))

        result = mongo_client.admin.command("ping")

        if int(result.get("ok")) == 1:
            print("Connected")
        else:
            raise Exception("Cluster ping returned OK != 1")
        app.mongo_client = mongo_client
        app.db = mongo_client.bigdata
    except Exception as e:
        print(e)


init_mongo_client(app)


@app.route("/", methods=["GET"])
def index():
    return "this is the cascade backend lesgooooooooo"


@app.route("/start_session", methods=["POST"])
def start_session():
    session_id = uuid4()
    app.db.sessions.insert_one(
        {
            "_id": str(session_id),
            "num_puzzles": 0,
            "current_puzzle": 0,
            "current_puzzle_attempts": 0,
            "skipped_puzzles": [],
            "score": 0,
        }
    )
    res = make_response(str(session_id))
    res.set_cookie("session_id", str(session_id))
    generate_puzzle(str(session_id))
    thread = Thread(target=generate_puzzle, args=[str(session_id)])
    thread.start()
    return res


@app.route("/<session_id>/target/<int:puzzle_num>")
def serve_image(session_id, puzzle_num):
    if not session_id:
        abort(403)
    # puzzle_num = app.db.sessions.find_one({"_id": session_id})[
    #     "current_puzzle"
    # ]
    file = app.db.puzzles.find_one({"_id": f"{session_id}.{puzzle_num}"})
    response = make_response(file["file"])
    response.headers.set("Content-Type", "image/png")
    return response


@app.route("/<session_id>/target/<int:puzzle_num>/points")
def get_puzzle_points(session_id, puzzle_num):
    puzzle = app.db.puzzles.find_one({"_id": f"{session_id}.{puzzle_num}"})
    return str(puzzle["points"])


@app.route("/<session_id>/skip", methods=["POST"])
def skip_puzzle(session_id):
    puzzle_num = app.db.sessions.find_one({"_id": session_id})[
        "current_puzzle"
    ]
    app.db.sessions.update_one(
        {"_id": session_id},
        {
            "$push": {"skipped_puzzles": puzzle_num},
            "$inc": {"current_puzzle": 1},
        },
    )
    thread = Thread(target=generate_puzzle, args=[session_id])
    thread.start()
    print(f"{puzzle_num + 1 = }")
    return str(puzzle_num + 1)


@app.route("/<session_id>/skipped")
def get_skipped(session_id):
    skipped_numbers = app.db.sessions.find_one({"_id": session_id})[
        "skipped_puzzles"
    ]

    res = [f"{session_id}.{num}" for num in skipped_numbers]
    return res


@app.route("/image/<name>")
def get_image(name):
    file = app.db.puzzles.find_one({"_id": name})
    response = make_response(file["file"])
    response.headers.set("Content-Type", "image/png")
    return response


@app.route("/solution/<name>")
def get_solution(name):
    solution = app.db.puzzles.find_one({"_id": name})["solution"]
    return solution


@app.route("/<session_id>/score")
def get_score(session_id):
    session = app.db.sessions.find_one({"_id": session_id})
    return str(session["score"])


@app.route("/<session_id>/submit", methods=["POST"])
def handle_submit(session_id):
    if not session_id:
        abort(403)
    session = app.db.sessions.find_one({"_id": session_id})
    score = session["score"]
    puzzle_num = session["current_puzzle"]

    data = request.get_json()
    html = data["html"]
    attempt_image = render_html(html)
    # attempt_name = f"{session_id}.{puzzle_num}.{attempt_num}"
    # app.db.puzzles.insert_one({"_id": attempt_name, "file": attempt_image})
    puzzle = app.db.puzzles.find_one({"_id": f"{session_id}.{puzzle_num}"})
    target_file = puzzle["file"]

    grading_res = requests.post(
        f"{GRADING_URL}/predict",
        files={
            "image1": ("target", target_file),
            "image2": ("attempt", attempt_image),
        },
    )

    print(f"{grading_res = }")
    print(f"{grading_res.text = }")
    grading_json = grading_res.json()
    sim_score = grading_json["similarity_score"]

    if sim_score > 0.7:  # correct
        puzzle_points = puzzle["points"]
        app.db.sessions.update_one(
            {"_id": session_id},
            {"$inc": {"current_puzzle": 1, "score": puzzle_points}},
        )

        thread = Thread(target=generate_puzzle, args=[session_id])
        thread.start()
        return {"status": "ok", "score": score + puzzle_points}

    app.db.sessions.update_one(
        {"_id": session_id}, {"$inc": {"current_puzzle_attempts": 1}}
    )
    return {"status": "error", "score": score}


# @app.route("/generate", methods=["GET"])
def generate_puzzle(session_id, theme=None, component=None):
    if not theme:
        theme = random.choice(THEMES)
    if not component:
        component = random.choice(COMPONENTS)

    context = f"Theme: {theme}, Component: {component}"
    print(f"{context = }")

    res = requests.post(
        BREADBOARD_URL,
        json={"$key": os.getenv("BREADBOARD-KEY"), "context": context},
    )
    print(f"{res.text = }")
    json_res = res.text[5:]
    data = json.loads(json_res)
    raw_output = data[1]["outputs"]["context"][-1]["parts"][0]["text"]
    raw_output_as_json = raw_output.strip("`json ")
    code_json = json.loads(raw_output_as_json)
    cleaned_html = code_json["html"].replace("\n", "")
    cleaned_css = code_json["css"].replace("\n", "")
    print(f"\n\n{cleaned_html = }")
    print(f"{cleaned_css = }\n\n")

    session = app.db.sessions.find_one({"_id": session_id})
    puzzle_num = session["num_puzzles"]

    combined_html = f"<style>{code_json['css']}</style>{code_json['html']}"
    image = render_html(combined_html)
    image_name = f"{session_id}.{puzzle_num}"

    app.db.puzzles.insert_one(
        {
            "_id": image_name,
            "file": image,
            "solution": combined_html,
            "points": len(combined_html) // 20,
        }
    )
    app.db.sessions.update_one(
        {"_id": session_id}, {"$inc": {"num_puzzles": 1}}
    )
    return image_name


@app.route("/foo")
def foo():
    files = [
        "brown big over.png",
        "small green blue.png",
        "apple apple one.png",
    ]
    for file in files:
        handle = open(file, "rb")
        app.db.puzzles.insert_one(
            {"_id": file, "file": handle, "solution": "foobar", "points": 20}
        )

================
File: backend/Procfile
================
web: gunicorn 'app:app'

================
File: backend/runtime.txt
================
python-3.12.6

================
File: frontend/app/globals.css
================
@import url("https://fonts.googleapis.com/css2?family=Inter:ital,opsz,wght@0,14..32,100..900;1,14..32,100..900&display=swap");
:root {
  --background: #cec7b3;
  --foreground: #171717;
}

html,
body {
  max-width: 100vw;
  overflow-x: hidden;
  font-family: Inter, sans-serif !important;
}

body {
  color: var(--foreground);
  background: var(--background);
  font-family: Arial, Helvetica, sans-serif;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

* {
  box-sizing: border-box;
  padding: 0;
  margin: 0;
}

a {
  color: inherit;
  text-decoration: none;
}

iframe {
  border: 0;
}

button.react-eyedrop-button {
  font-weight: bold;
  border: 0;
  padding: 0.5rem 1rem;
  background: transparent;
  border-radius: 0;
  color: #000;
  font-size: 1.25rem;
  transition: all 500ms linear;
  cursor: pointer;
  position: relative;
  left: 50%;
  transform: translateX(-50%);
}
button.react-eyedrop-button:hover {
  /* font-weight: bold; */
  background: rgba(100, 141, 71, 0.1);
  /* color: #999; */
}

button {
  font-family: Inter, sans-serif;
}

================
File: frontend/app/layout.js
================
import { StoreProvider } from "../store/storeProvider";
import "./globals.css";

export const metadata = {
  title: "Cascade",
  description: "Generated by create next app",
};

export default function RootLayout({ children }) {
  return (
    <html lang="en">
      {/* <body> */}
      <body>
        <StoreProvider>{children}</StoreProvider>
      </body>
      {/* </body> */}
    </html>
  );
}

================
File: frontend/app/page.js
================
"use client";

import styles from "./page.module.css";
import Home from "../components/views/home";
import Start from "../components/views/start";
import End from "../components/views/end";
import { useSelector } from "react-redux";

export default function Root() {
  const pageState = useSelector((state) => state.example.value);
  return (
    <>
      {pageState === "start" && <Start />}
      {pageState === "home" && <Home />}
      {pageState === "end" && <End />}
    </>
  );
}

================
File: frontend/app/page.module.css
================
.container {
  display: flex;
  gap: 1rem;
  width: 100%;
  height: 100vh;
}

.previewContainer {
  display: flex;
  gap: 1rem;
  flex-direction: column;
}

.editorContainer {
  display: flex;
  gap: 1rem;
  flex-direction: column;
  flex-grow: 1;
  height: 100%;
}

.htmlEditor {
  flex-shrink: 1;
}
.cssEditor {
  flex-grow: 1;
}
.preview {
  height: 300px;
  width: 300px;
}

================
File: frontend/components/views/end.jsx
================
import "../../styles/end.css";
import { useState, useEffect } from "react";
import Image from "next/image";
import { toStart } from "../../store/exampleSlice";
import { useDispatch } from "react-redux";
import { useSelector } from "react-redux";

const BACKEND = "http://127.0.0.1:5000";

function End() {
  const [isOpen, setIsOpen] = useState(false);
  const [score, setScore] = useState();
  const dispatch = useDispatch();
  const sessionId = { payload: localStorage.getItem("sessionId") };

  // dropdown data
  const [skippedNames, setSkippedNames] = useState([]);
  const [skippedCode, setSkippedCode] = useState([]);

  async function fetchData() {
    let data;
    try {
      const response = await fetch(`${BACKEND}/${sessionId.payload}/skipped`);
      if (!response.ok) {
      }
      data = await response.json(); // Assume the backend sends JSON
      setSkippedNames(data); // Step 3: Update state with fetched data
    } catch (error) {
      console.error("Fetch error:", error);
    }

    const skippedCode = [];
    for (const skippedName of data) {
      const codeRes = await fetch(`${BACKEND}/solution/${skippedName}`);
      const code = await codeRes.text();
      skippedCode.append(code);
    }
    console.log("skippedCode", skippedCode);

    setSkippedCode(skippedCode);

    const scoreResponse = await fetch(`${BACKEND}/${sessionId.payload}/score`);
    const endScore = await scoreResponse.text();
    setScore(endScore);
  }

  useEffect(() => {
    if (sessionId) {
      fetchData();
    }
  }, [sessionId]);

  const toggleDropdown = () => {
    setIsOpen(!isOpen);
  };

  function handleReturn() {
    dispatch(toStart());
  }

  return (
    <div>
      {sessionId.payload}
      <div style={{ textAlign: "center", marginTop: "20px" }}>
        <Image src="/logo.png" width={300} height={300} />
        {/* <h1>your score was {score}</h1> */}
        <h1>time's up!</h1>
      </div>
      <div style={{ textAlign: "center", marginBottom: "20px" }}>
        <span
          style={{
            cursor: "pointer",
            display: "inline-flex",
            alignItems: "center",
          }}
          onClick={toggleDropdown}
        >
          practice again?
          <span
            style={{
              marginLeft: "8px",
              transform: isOpen ? "rotate(180deg)" : "rotate(0deg)",
              transition: "transform 0.2s",
            }}
          >
            ▼
          </span>
        </span>

        {/* Content that gets toggled */}
        {isOpen && (
          <div style={{ marginTop: "8px" }} className="dropdown">
            {skippedNames.map((name, index) => (
              // `${BACKEND}/image/${sessionId}`
              // `${BACKEND}/solution/${sessionId}`
              <div key={name}>
                <img
                  src={`${BACKEND}/image/${name}`}
                  alt={`image of problem ${name}`}
                />
                <pre>{skippedCode[index]}</pre>
              </div>
            ))}
          </div>
        )}
      </div>
      <div style={{ textAlign: "center" }}>
        <button
          style={{ position: "relative", fontWeight: "bold", color: "FDFAE0" }}
          className="returnButton"
          onClick={handleReturn}
        >
          Home
        </button>
      </div>
    </div>
  );
}

export default End;

================
File: frontend/components/views/home.jsx
================
import React, { useState, useEffect, useCallback } from "react";
import styles from "../../styles/home.module.css";
import CodeMirror from "@uiw/react-codemirror";
import { loadLanguage } from "@uiw/codemirror-extensions-langs";
import { tokyoNight } from "@uiw/codemirror-theme-tokyo-night";
import { EyeDropper } from "react-eyedrop";
import DOMPurify from "dompurify";
import { useDispatch } from "react-redux";
import { toEnd } from "../../store/exampleSlice";
import Timer from "./Timer";

const BACKEND = "http://127.0.0.1:5000";

const INITIALCSS = `
body {
  background: white
}
div {
  height: 100px;
  width: 100px;
  background: #00274C;
  color: #FFCB05
}
`;

const Home = () => {
  const [loading, setLoading] = useState(false);
  const [css, setCss] = useState(INITIALCSS);
  const [html, setHtml] = useState("<div>hello</div>");
  const dispatch = useDispatch();

  function handleTimerExpire() {
    dispatch(toEnd(sessionId));
  }

  function generatePreviewHtml() {
    return `<html><style>body { margin: 0; height: 300px; width: 300px; } ${css}</style>${DOMPurify.sanitize(
      html
    )}</html>`;
  }

  const [sessionId, setSessionId] = useState();
  const [puzzleNum, setPuzzleNum] = useState(0);
  const [puzzlePoints, setPuzzlePoints] = useState();
  const [sessionScore, setSessionScore] = useState(0);
  const [attemptNum, setAttemptNum] = useState(0);
  const [celebrationText, setCelebrationText] = useState("");

  useEffect(() => {
    if (!sessionId) {
      handleStart();
      sessionStorage.setItem("sessionId", sessionId);
    }
  }, [sessionId]);

  async function handleStart() {
    if (loading) {
      return;
    }
    setLoading(true);
    setPuzzleNum(0);
    const res = await fetch(`${BACKEND}/start_session`, { method: "POST" });
    const newSessionId = await res.text();
    console.log("newSessionId", newSessionId);
    setSessionId(newSessionId);
    setLoading(false);
  }

  async function updatePuzzlePoints() {
    const res = await fetch(
      `${BACKEND}/${sessionId}/target/${puzzleNum}/points`
    );
    const t = await res.text();
    setPuzzlePoints(t);
  }

  useEffect(() => {
    if (sessionId) {
      updatePuzzlePoints();
    }
  }, [puzzleNum, sessionId]);

  async function handleSubmit() {
    const res = await fetch(`${BACKEND}/${sessionId}/submit`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json", // Set appropriate content type
      },
      body: JSON.stringify({
        puzzle_id: "test",
        html: generatePreviewHtml(),
      }),
    });
    const resJson = await res.json();
    if (resJson.status === "ok") {
      setPuzzleNum((oldPuzzleNum) => oldPuzzleNum + 1);
      setSessionScore(resJson.score);
      setCelebrationText(`Passed! Your score is now ${resJson.score}`);
      setTimeout(() => setCelebrationText(""), 3000);
    } else {
      setAttemptNum((oldAttemptNum) => oldAttemptNum + 1);
    }
  }

  // for skip button
  const [isDisabled, setIsDisabled] = useState(true);
  const [timerKey, setTimerKey] = useState(0);
  useEffect(() => {
    const timer = setTimeout(() => {
      setIsDisabled(false);
    }, 5000); // in ms
    return () => clearTimeout(timer);
  }, [timerKey]);

  const handleCssEditorChange = useCallback((val, viewUpdate) => {
    setCss(val);
  });

  const handleHtmlEditorChange = useCallback((val, viewUpdate) => {
    setHtml(val);
  });

  async function handleSkip() {
    setIsDisabled(true); // Disable the button again after click

    // Set a timeout to re-enable it after 5 seconds
    setTimeout(() => {
      setIsDisabled(false);
    }, 5000);
    const res = await fetch(`${BACKEND}/${sessionId}/skip`, {
      method: "POST",
    });
    if (res.ok) {
      setPuzzleNum((oldPuzzleNum) => oldPuzzleNum + 1);
    }
  }

  function handleEnd() {
    dispatch(toEnd(sessionId));
  }

  const [pickedColor, setPickedColor] = useState({ rgb: "", hex: "" });
  const [eyedropOnce] = useState(true); // only 1 use of the eyedropper per button press
  const handleChangeColor = ({ rgb, hex }) => {
    setPickedColor({ rgb, hex });
    navigator.clipboard.writeText(hex);
  };

  return (
    <div className={styles.container}>
      <div style={{ marginLeft: "auto" }}>
        <div className={styles.colorContainer}>
          <EyeDropper
            onChange={handleChangeColor}
            cursorActive="crosshair"
            className={styles.eyedropperButton}
          >
            pick color
          </EyeDropper>
          <div style={{ display: "flex", gap: "1rem", width: "100%" }}>
            <div
              className={styles.colorDrop}
              style={{ backgroundColor: pickedColor.hex }}
            />
            <div>
              <p>{pickedColor.rgb}</p>
              <p>{pickedColor.hex}</p>
            </div>
          </div>
        </div>
        <div className={styles.previewContainer}>
          <img
            src={`${BACKEND}/${sessionId}/target/${puzzleNum}`}
            // src="https://corsproxy.io/?https://placewaifu.com/image/300"
            alt="target"
            className={styles.targetImage}
          />
          <iframe
            className={styles.preview}
            srcDoc={generatePreviewHtml()}
          ></iframe>{" "}
        </div>
      </div>

      <div className={styles.editorContainer}>
        <div className={styles.buttonContainer}>
          <div style={{ display: "flex", gap: "1rem", alignItems: "center" }}>
            <Timer onExpire={handleTimerExpire} length={3 * 60 * 1000} />
            {sessionScore ? <div>{sessionScore} points this run</div> : <></>}
          </div>
          <div>
            <b>
              puzzle {puzzleNum}
              {puzzlePoints ? ` (${puzzlePoints} pts) ` : ""}
            </b>
            , attempt {attemptNum}
          </div>
        </div>
        <CodeMirror
          className={styles.htmlEditor}
          value={html}
          theme={tokyoNight}
          maxHeight="200px"
          extensions={[loadLanguage("html")]}
          onChange={handleHtmlEditorChange}
        />
        <div className={styles.cssEditor}>
          <CodeMirror
            value={css}
            height="30rem"
            theme={tokyoNight}
            extensions={[loadLanguage("css")]}
            onChange={handleCssEditorChange}
          />
          {celebrationText}
        </div>
        <div className={styles.buttonContainer}>
          {/* <button
            onClick={handleStart}
            className={styles.gameButton}
            disabled={loading}
          >
            Start
          </button> */}
          <div className={styles.buttonGroup}>
            <button
              className={`${styles.gameButton} ${styles.gameButtonDanger}`}
              onClick={handleEnd}
            >
              {"End game"}
            </button>
            <button
              className={styles.gameButton}
              disabled={isDisabled}
              onClick={handleSkip}
            >
              {isDisabled ? "Wait..." : "Skip"}
            </button>
          </div>
          <button
            className={`${styles.gameButton} ${styles.gameButtonPrimary}`}
            onClick={handleSubmit}
          >
            Submit
          </button>
        </div>
      </div>
    </div>
  );
};

export default Home;

================
File: frontend/components/views/start.jsx
================
import "../../styles/start.css";
import Image from "next/image";
import { useState } from "react";
import { useDispatch } from "react-redux";
import { toHome } from "../../store/exampleSlice";

const BACKEND = "http://127.0.0.1:5000";

const Start = (page) => {
  const dispatch = useDispatch();

  async function handleStart() {
    dispatch(toHome());
  }
  return (
    <div>
      <div style={{ textAlign: "center", marginTop: "20px" }}>
        <Image src="/logo.png" width={300} height={300} alt="logo" />
        <h1 style={{ fontWeight: "800" }}>cascade</h1>
        <p>train your CSS skills!</p>
      </div>
      <div className="container">
        <p style={{ width: "600px", marginBottom: "20px", marginTop: "30px" }}>
          Recreate as many images as you can in three minutes. If you get stuck,
          use the skip button after five seconds.
        </p>
        <p
          style={{ width: "600px", marginBottom: "20px", marginBotom: "30px" }}
        >
          All distances are multiples of 10px.
        </p>
        <button
          style={{ position: "relative", fontWeight: "bold" }}
          className="startButton"
          onClick={handleStart}
        >
          Go!
        </button>
      </div>
    </div>
  );
};

export default Start;

================
File: frontend/components/views/Timer.jsx
================
import React from "react";
import { useTimer } from "react-timer-hook";
import styles from "../../styles/timer.module.css";

export default function Timer({ length, onExpire }) {
  const { minutes, seconds, isRunning } = useTimer({
    expiryTimestamp: new Date(new Date().getTime() + length),
    onExpire,
  });
  return (
    <div className={styles.timer}>
      {minutes.toLocaleString("en-US", {
        minimumIntegerDigits: 2,
        useGrouping: false,
      })}
      :
      {seconds.toLocaleString("en-US", {
        minimumIntegerDigits: 2,
        useGrouping: false,
      })}
    </div>
  );
}

================
File: frontend/store/exampleSlice.js
================
// store/exampleSlice.js
import { createSlice } from "@reduxjs/toolkit";

// Initial state
const initialState = {
  value: "start",
  sessionId: "",
};

// Create a slice
const exampleSlice = createSlice({
  name: "example",
  initialState,
  reducers: {
    toHome: (state) => {
      state.value = "home";
    },
    toStart: (state) => {
      state.value = "start";
    },
    toEnd: (state, sessionId) => {
      state.value = "end";
      state.sessionId = sessionId;
    },
  },
});

// Export actions
export const { toHome, toStart, toEnd } = exampleSlice.actions;

// Export the reducer
export default exampleSlice.reducer;

================
File: frontend/store/store.js
================
// store/store.js
import { configureStore } from '@reduxjs/toolkit';
import { combineReducers } from 'redux';
import exampleReducer from './exampleSlice';

// Combine multiple reducers here if needed
const rootReducer = combineReducers({
  example: exampleReducer, // Add other reducers here
});

// Set up Redux store
export const store = configureStore({
  reducer: rootReducer,
});

export default store;

================
File: frontend/store/storeProvider.js
================
// store/storeProvider.js
'use client'; // This is required for Client-side components in Next.js 13

import { Provider } from 'react-redux';
import { store } from './store';

// This is a wrapper to provide the Redux store to your app
export function StoreProvider({ children }) {
  return <Provider store={store}>{children}</Provider>;
}

================
File: frontend/styles/end.css
================
.container {
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    text-align: center;
  }
.returnButton {
    background-color: #FDFAE0;
    border: none;
    color: black;
    padding: 20px;
    text-align: center;
    text-decoration: none;
    display: inline-block;
    font-size: 16px;
    margin: 4px 2px;
    width: 300px;
    border-radius: 12px;
    box-shadow: 5px 5px 5px black;
  }
  .returnButton:active {
    top: 2px;
    left: 1px;
    box-shadow: none;
  }
  .dropdown {
    display: flex;
    flex-direction: row;
    justify-content: center;
  }

h1 {
    font-weight: bold;
    font-size: 50px;
    margin-bottom: 20px;
  }

================
File: frontend/styles/home.module.css
================
.container {
  display: grid;
  grid-template-columns: repeat(2, 1fr); /* Create two equal-width columns */
  gap: 20px; /* Add spacing between the grid items */
  padding: 20px; /* Add padding around the grid */
  height: 100vh;
  padding: 2rem;
  margin-right: 10rem;
}

.previewContainer {
  display: flex;
  gap: 1rem;
  flex-direction: column;
}

.preview,
.targetImage {
  width: 300px;
  height: 300px;
}

.editorContainer {
  display: flex;
  gap: 1rem;
  flex-direction: column;
  flex-grow: 1;
  height: 100%;
}

.htmlEditor {
  margin-left: 5rem;
  flex-shrink: 1;
  width: 40rem;
}
.cssEditor {
  margin-left: 5rem;
  flex-grow: 1;
  width: 40rem;
}
.preview {
  height: 300px;
  width: 300px;
}

.eyedropperButton {
  background: blue;
}

/* an attempt at making the eyedropper button look nicer
  .custom-eyedropper {
    background-color: #4CAF50;
    color: white;
    padding: 10px 20px;
    font-size: 16px;
    border: none;
    border-radius: 5px;
    cursor: pointer;
  } */
.gameButton {
  border: none;
  color: black;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 16px;
  margin: 4px 2px;
  border-radius: 0.5rem;
  background-color: "#FDFAE0";
  /* box-shadow: 2px 2px 2px black; */
  padding: 0.75rem 1rem;
  font-weight: 600;
  min-width: 100px;
  cursor: pointer;
  transition: all 300ms ease-in-out;
}
.gameButton:hover {
  opacity: 0.8;
}
.gameButton:disabled {
  cursor: not-allowed;
  opacity: 0.4;
}
button.gameButtonPrimary {
  color: white;
  background: #60cae3;
}
button.gameButtonDanger {
  color: white;
  background: #e46962;
}
.gameButton:active {
  top: 2px;
  left: 1px;
  box-shadow: none;
}

.colorContainer {
  width: 20rem;
  background: #c1b9a7;
  border-radius: 1rem;
  margin-bottom: 1rem;
  padding: 1rem;
  align-items: center;
  display: flex;
  flex-direction: column;
  gap: 0.5rem;
}

.colorDrop {
  /* border-radius: 100%; */
  width: 2.5rem;
  height: 2.5rem;
}

.buttonContainer {
  margin-left: 5rem;
  display: flex;
  width: 100%;
  justify-content: space-between;
}

.buttonGroup {
  display: flex;
  gap: 1rem;
}

================
File: frontend/styles/start.css
================
.container {
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    text-align: center;
  }
.startButton {
    background-color: #58C9E2;
    border: none;
    color: black;
    padding: 20px;
    text-align: center;
    text-decoration: none;
    display: inline-block;
    font-size: 16px;
    margin: 4px 2px;
    width: 300px;
    border-radius: 12px;
    box-shadow: 5px 5px 5px black;
  }
  .startButton:active {
    top: 2px;
    left: 1px;
    box-shadow: none;
  }

h1 {
    font-weight: bold;
    font-size: 50px;
    margin-bottom: 10px;
  }

================
File: frontend/styles/timer.module.css
================
.timer {
  padding: 0.5rem;
  border-radius: 0.25rem;
  background: rgba(0, 0, 0, 0.1);
}

================
File: frontend/.eslintrc.json
================
{
  "extends": ["next/babel", "next/core-web-vitals"]
}

================
File: frontend/.gitignore
================
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules
/.pnp
.pnp.js
.yarn/install-state.gz

# testing
/coverage

# next.js
/.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# local env files
.env*.local

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts

================
File: frontend/jsconfig.json
================
{
  "compilerOptions": {
    "paths": {
      "@/*": ["./*"]
    }
  }
}

================
File: frontend/next.config.mjs
================
/** @type {import('next').NextConfig} */
const nextConfig = {};

export default nextConfig;

================
File: frontend/package.json
================
{
  "name": "frontend",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "@reduxjs/toolkit": "^2.2.7",
    "@uiw/codemirror-extensions-langs": "^4.23.3",
    "@uiw/codemirror-theme-tokyo-night": "^4.23.3",
    "@uiw/react-codemirror": "^4.23.3",
    "dompurify": "^3.1.7",
    "lodash": "^4.17.21",
    "next": "14.2.13",
    "react": "^18",
    "react-dom": "^18",
    "react-eyedrop": "^5.5.1",
    "react-redux": "^9.1.2",
    "react-timer-hook": "^3.0.7",
    "sharp": "^0.33.5"
  },
  "devDependencies": {
    "eslint": "^8",
    "eslint-config-next": "14.2.13"
  }
}

================
File: frontend/README.md
================
This is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

You can start editing the page by modifying `app/page.js`. The page auto-updates as you edit the file.

This project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.

================
File: model/css_dataset/reference_styles.css
================
.container {
    width: 300px;
    height: 200px;
    background-color: #3498db;
    position: relative;
    color: white;
}

================
File: model/css_dataset/variant_styles_1.css
================
.container {
    width: 300px;
    height: 200px;
    background-color: #3498db;
    position: absolute;
    color: black;
}

================
File: model/legacy/host_images.py
================
from flask import Flask
app = Flask(__name__)

@app.route('/')
def home():
    return ""

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=3000)

================
File: model/legacy/training_data.py
================
"""For large-scale dataset generation, use generate_data.py."""

import os 
from dotenv import load_dotenv
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By

load_dotenv()

temp_html_file_path = os.getenv("TEMP_HTML_FILE_PATH")

options = Options()
options.headless = True  
driver = webdriver.Chrome(options=options)
# rendering on high-DPI screens can inflate dimensions
device_pixel_ratio = driver.execute_script("return window.devicePixelRatio;")

html_content = '''
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Temporary CSS render</title>
    <style>
        .screenshot-div {
            width: 150px;
            height: 150px;
            background-color: lightblue;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 24px;
            color: white;
            border: 2px solid blue;
        }
    </style>
</head>
<body>
    <div class="screenshot-div">This is not a test div</div>
</body>
</html>
'''

with open('temp.html', 'w') as file:
    file.write(html_content)

driver.get(f"file://{temp_html_file_path}") 

div_element = driver.find_element(By.CLASS_NAME, "screenshot-div")
location = div_element.location
size = div_element.size
driver.save_screenshot("dataset/reference3.png")  

# crop screenshot
from PIL import Image

x = location['x']
y = location['y']
width = size['width']
height = size['height']

print(x, y, width, height)

full_image = Image.open("dataset/reference3.png")
cropped_image = full_image.crop((0, 0, 400, 400))
cropped_image.save("dataset/reference3_cropped.png")

driver.quit()

print("Screenshot saved as dataset/reference2_cropped.png")

================
File: model/.gitignore
================
.env
../backend/env/
env/
dataset/
siamese.h5

================
File: model/generate_data.py
================
"""Fast heuristic for Wayne's generative approach, suitable for large-scale dataset generation."""

import random
import re
from html2image import Html2Image
from PIL import Image
import os

corpus = [
    "the", "quick", "brown", "fox", "jumps", "over", "lazy", "dog", "cat", "on", "off", "and", 
    "in", "out", "a", "big", "small", "green", "blue", "red", "apple", "banana", "tree", "house", 
    "runs", "eats", "sleeps", "flies", "swims", "laughs", "cries", "walks", "talks"
]

def randomize_capitalization(word):
    return random.choice([word.lower(), word.upper(), word.capitalize()])

def random_sentence(min, max):
    word_count = random.randint(min, max)
    sentence = [randomize_capitalization(random.choice(corpus)) for _ in range(word_count)]
    return ' '.join(sentence)

def random_color():
    return f"#{random.randint(0, 0xFFFFFF):06x}"

def random_length(max_value=400):
    return f"{random.randint(50, max_value)}px" 

def random_border_radius():
    return f"{random.randint(0, 50)}px"  

def random_box_shadow():
    x_offset = random.randint(-20, 20)
    y_offset = random.randint(-20, 20)
    blur_radius = random.randint(5, 30)
    shadow_color = random_color()
    return f"{x_offset}px {y_offset}px {blur_radius}px {shadow_color}"

def random_text_alignment():
    return random.choice(["left", "center", "right", "justify"])

def random_position(length, width, container_size=400):
    max_top = container_size - int(length[:-2])
    max_left = container_size - int(width[:-2]) 
    return f"top: {random.randint(0, max_top)}px; left: {random.randint(0, max_left)}px;"

def random_css():
    length = random_length(350)
    width = random_length(350)
    
    css_ruleset = {
        "position": "absolute", 
        "color": random_color(),
        "background-color": random_color(), 
        "length": length,
        "width": width,
        "border-radius": random_border_radius(),
        "box-shadow": random_box_shadow(),
        "text-align": random_text_alignment(),
        "positioning": random_position(length, width),
        "content": random_sentence(3, 7),
    }

    return css_ruleset

def format_css(css_ruleset):
    css_string = f"""
    .random-div {{
        position: {css_ruleset['position']};
        {css_ruleset['positioning']}
        width: {css_ruleset['width']};
        height: {css_ruleset['length']};
        background-color: {css_ruleset['background-color']};
        color: {css_ruleset['color']};
        border-radius: {css_ruleset['border-radius']};
        box-shadow: {css_ruleset['box-shadow']};
        text-align: {css_ruleset['text-align']};
        display: flex;
        justify-content: center;
        align-items: center;
    }}

    .random-div::before {{
        content: {css_ruleset['content']};
    }}
    """
    return css_string

def format_html_css(css_ruleset):
    html_css_string = f"""
    <html>
    <head>
        <style>
        body {{
            width: 400px;
            height: 400px;
            position: relative;
            margin: 0;
            padding: 0;
            background-color: #f0f0f0;
        }}
        .random-div {{
            position: {css_ruleset['position']};
            {css_ruleset['positioning']}
            width: {css_ruleset['width']};
            height: {css_ruleset['length']};
            background-color: {css_ruleset['background-color']};
            color: {css_ruleset['color']};
            border-radius: {css_ruleset['border-radius']};
            box-shadow: {css_ruleset['box-shadow']};
            text-align: {css_ruleset['text-align']};
            display: flex;
            justify-content: center;
            align-items: center;
            font-family: Arial, sans-serif;
            font-size: 18px;
        }}
        </style>
    </head>
    <body>
        <div class="random-div">{css_ruleset['content']}</div>
    </body>
    </html>
    """
    return html_css_string

def html_to_png(html_content, output_filename="temp.png"):
    hti = Html2Image()
    hti.screenshot(html_str=html_content, save_as=output_filename)
    print(f"Image saved as {output_filename}")

def text_discrepancy(sentence):
    words = sentence.split()
    if len(words) > 1:
        if random.random() > 0.5:
            idx1, idx2 = random.sample(range(len(words)), 2)
            words[idx1], words[idx2] = words[idx2], words[idx1] 
        else:
            idx = random.randint(0, len(words) - 1)
            words[idx] = ''.join(random.sample(words[idx], len(words[idx]))) 
    return ' '.join(words)

def color_discrepancy(color):
    color = color.lstrip('#')
    rgb = tuple(int(color[i:i+2], 16) for i in (0, 2, 4))
    rgb = tuple(min(255, max(0, x + random.randint(-30, 30))) for x in rgb)
    return f"#{rgb[0]:02x}{rgb[1]:02x}{rgb[2]:02x}"

def length_discrepancy(length):
    value = int(length[:-2])
    value = int(value * random.uniform(0.9, 1.1))
    return f"{value}px"

def text_alignment_discrepancy(alignment):
    possible_alignments = ["left", "center", "right", "justify"]
    possible_alignments.remove(alignment) 
    return random.choice(possible_alignments)

def shadow_discrepancy(shadow):
    parts = shadow.split()
    x_offset = int(parts[0][:-2]) + random.randint(-5, 5)
    y_offset = int(parts[1][:-2]) + random.randint(-5, 5)
    blur_radius = int(parts[2][:-2]) + random.randint(-5, 5)
    color = color_discrepancy(parts[3])
    return f"{x_offset}px {y_offset}px {blur_radius}px {color}"

def discrepancies(css_ruleset):
    css_faulty = css_ruleset.copy()
    
    css_faulty['content'] = text_discrepancy(css_faulty['content'])
    css_faulty['color'] = color_discrepancy(css_faulty['color'])
    css_faulty['background-color'] = color_discrepancy(css_faulty['background-color'])
    css_faulty['length'] = length_discrepancy(css_faulty['length'])
    css_faulty['width'] = length_discrepancy(css_faulty['width'])
    css_faulty['text-align'] = text_alignment_discrepancy(css_faulty['text-align'])
    css_faulty['box-shadow'] = shadow_discrepancy(css_faulty['box-shadow'])
    
    return css_faulty

if "__main__" == __name__:
    # for i in range(500, 501):
        # filename = f"dataset/ref_{i}_right.png"
        # css_ruleset = random_css()
        # css_string = format_css(css_ruleset)
        # html_css_string = format_html_css(css_ruleset)
        # html_to_png(html_css_string)

        # full_image = Image.open("temp.png")
        # cropped_image = full_image.crop((0, 0, 400, 400))
        # cropped_image.save(filename)

        # filename = f"dataset/ref_{i}_wrong.png"
        # css_faulty = discrepancies(css_ruleset)
        # css_string_faulty = format_css(css_faulty)
        # html_css_string_faulty = format_html_css(css_faulty)
        # html_to_png(html_css_string_faulty)

        # full_image = Image.open("temp.png")
        # cropped_image = full_image.crop((0, 0, 400, 400))
        # cropped_image.save(filename)

        # print("Done with iteration", i)
    filename = f"test_right.png"
    css_ruleset = random_css()
    css_string = format_css(css_ruleset)
    html_css_string = format_html_css(css_ruleset)
    html_to_png(html_css_string)

    full_image = Image.open("temp.png")
    cropped_image = full_image.crop((0, 0, 400, 400))
    cropped_image.save(filename)

    filename = f"test_wrong.png"
    css_ruleset["positioning"] = re.sub(r'top:\s*(\d+)px', lambda m: f"top: {int(m.group(1)) + 2}px", css_ruleset["positioning"])
    css_faulty = css_ruleset
    css_string_faulty = format_css(css_faulty)
    html_css_string_faulty = format_html_css(css_faulty)
    html_to_png(html_css_string_faulty)

    full_image = Image.open("temp.png")
    cropped_image = full_image.crop((0, 0, 400, 400))
    cropped_image.save(filename)

================
File: model/siamese_app.py
================
from flask import Flask, request, jsonify
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image

# Initialize Flask app
app = Flask(__name__)

# Load your Siamese model (ensure siamese.h5 is in the same directory)
model = load_model('siamese.h5')

# Preprocess image function (adjust based on your model's requirements)
def preprocess_image(img_path, target_size=(400, 400)):
    img = image.load_img(img_path, target_size=target_size)
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis=0)  # Add batch dimension
    img = img / 255.0  # Normalize pixel values (if needed)
    return img

# Define the route for running the Siamese model
@app.route('/predict', methods=['POST'])
def run_siamese_model():
    # Get the image paths from the request (or upload the images via form-data)
    image1_path = request.form.get('image1')
    image2_path = request.form.get('image2')

    # Preprocess the images
    img1 = preprocess_image(image1_path)
    img2 = preprocess_image(image2_path)

    # Run the Siamese network
    prediction = model.predict([img1, img2])

    # Return the prediction result as JSON
    return jsonify({'similarity_score': float(prediction[0])})

# Start the Flask server
if __name__ == '__main__':
    app.run(debug=True)

================
File: model/test_model.py
================
# tensorflow.keras loaded lazily - ide may give resolution errors
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image

import numpy as np
print("beep boop before")
model = load_model('siamese.h5')
print("beep boop after")

def preprocess_image(img_path):
    img = image.load_img(img_path, target_size=(400, 400))
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = img / 255.0
    return img

image1_path = "test_right.png"
image2_path = "test_wrong.png"

image1 = preprocess_image(image1_path)
image2 = preprocess_image(image2_path)

input_pair = [image1, image2]

prediction = model.predict(input_pair)
print(f"Prediction: {prediction}")

================
File: model/train_siamese.ipynb
================
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee080a26-8f36-4678-a658-828fa73f6412",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "If running in ITDC, Jupyter might complain about not finding CUDA drivers - we disregard this because we're not using a CUDA GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cac80b1-efb7-47b3-b8a3-f637ed3235ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-29 02:40:01.430741: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-29 02:40:01.626681: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-29 02:40:01.703956: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-29 02:40:01.704004: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-29 02:40:01.705634: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-29 02:40:01.715977: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-29 02:40:01.716653: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-29 02:40:03.139504: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-09-29 02:40:05.872853: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /tensorflow/core/bfc_allocator_delay. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.\n",
      "2024-09-29 02:40:05.873119: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /xla/service/gpu/compiled_programs_count. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.\n",
      "2024-09-29 02:40:05.874611: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /jax/pjrt/pjrt_executable_executions. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.\n",
      "2024-09-29 02:40:05.874629: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /jax/pjrt/pjrt_executable_execution_time_usecs. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.\n",
      "2024-09-29 02:40:07.563190: I itex/core/wrapper/itex_gpu_wrapper.cc:38] Intel Extension for Tensorflow* GPU backend is loaded.\n",
      "2024-09-29 02:40:07.566670: I external/local_xla/xla/pjrt/pjrt_api.cc:67] PJRT_Api is set for device type xpu\n",
      "2024-09-29 02:40:07.566688: I external/local_xla/xla/pjrt/pjrt_api.cc:72] PJRT plugin for XPU has PJRT API version 0.33. The framework PJRT API version is 0.34.\n",
      "2024-09-29 02:40:07.593776: I external/intel_xla/xla/stream_executor/sycl/sycl_gpu_runtime.cc:134] Selected platform: Intel(R) Level-Zero\n",
      "2024-09-29 02:40:07.593808: I external/intel_xla/xla/stream_executor/sycl/sycl_gpu_runtime.cc:159] number of sub-devices is zero, expose root device.\n",
      "2024-09-29 02:40:07.595860: I external/xla/xla/service/service.cc:168] XLA service 0x55bf5f5d6570 initialized for platform SYCL (this does not guarantee that XLA will be used). Devices:\n",
      "2024-09-29 02:40:07.595887: I external/xla/xla/service/service.cc:176]   StreamExecutor device (0): Intel(R) Data Center GPU Max 1100, <undefined>\n",
      "2024-09-29 02:40:07.596062: I itex/core/devices/gpu/itex_gpu_runtime.cc:130] Selected platform: Intel(R) Level-Zero\n",
      "2024-09-29 02:40:07.596075: I itex/core/devices/gpu/itex_gpu_runtime.cc:155] number of sub-devices is zero, expose root device.\n",
      "2024-09-29 02:40:07.596768: I external/intel_xla/xla/pjrt/se_xpu_pjrt_client.cc:97] Using BFC allocator.\n",
      "2024-09-29 02:40:07.596790: I external/xla/xla/pjrt/gpu/gpu_helpers.cc:106] XLA backend allocating 46385646796 bytes on device 0 for BFCAllocator.\n",
      "2024-09-29 02:40:07.609305: I external/local_xla/xla/pjrt/pjrt_c_api_client.cc:119] PjRtCApiClient created.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d658bbd3-aec0-4a7a-abfb-771964ea5fb1",
   "metadata": {},
   "source": [
    "# Base model\n",
    "To construct the Siamese neural network, we're using two [VGG16 models](https://arxiv.org/abs/1409.1556) as feature extractors. All input images are 400x400 pixels with 3 color channels. To minimize computational cost, we freeze the pretrained CNN layers and train only the final comparison layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e8558e5-ebd4-4569-9f4c-9bee73518a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-29 02:40:13.629272: I tensorflow/core/common_runtime/next_pluggable_device/next_pluggable_device_factory.cc:118] Created 1 TensorFlow NextPluggableDevices. Physical device type: XPU\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(400, 400, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a33b79-b536-44b8-80d3-3907a27672e3",
   "metadata": {},
   "source": [
    "# Siamese network construction\n",
    "\n",
    "We extract features for both images, flatten them, and compute their difference. This is fed into the fully-connected comparison layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9f32f20-4450-47b2-9510-4d9ddc7a3d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_comparison_model():\n",
    "    input_1 = layers.Input(shape=(400, 400, 3))\n",
    "    input_2 = layers.Input(shape=(400, 400, 3))\n",
    "\n",
    "    features_1 = base_model(input_1)\n",
    "    features_2 = base_model(input_2)\n",
    "\n",
    "    flattened_1 = layers.Flatten()(features_1)\n",
    "    flattened_2 = layers.Flatten()(features_2)\n",
    "\n",
    "    subtract = layers.Subtract()([flattened_1, flattened_2])\n",
    "    \n",
    "    x = layers.Dense(256, activation='relu')(subtract)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[input_1, input_2], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c374f27f-93a8-4c67-a0e0-f524fd370289",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_model = build_comparison_model()\n",
    "comparison_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a54260-d9d4-41b4-b479-e85a58471d0c",
   "metadata": {},
   "source": [
    "# Loading the dataset\n",
    "The model trains on a dataset of 2000 images - one correct and one marginally incorrect (labeled) image pair for each of 500 CSS sample rulesets. See `generate_data.py` for generation of training data. Note that each reference `i` only has two *distinct* associated images:\n",
    "\n",
    "`(ref_i_right.png, ref_i_wrong.png), (ref_i_right.png, ref_i_right.png)`\n",
    "\n",
    "So, for space efficiency, we only store `ref_i_right.png` and `ref_i_wrong.png` and construct the lists of image paths manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fb32662-3caf-4c7a-8987-a593aa02feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, (400, 400))\n",
    "    return image / 255.0\n",
    "\n",
    "def load_pairs(image1_path, image2_path, label):\n",
    "    image1 = load_image(image1_path)\n",
    "    image2 = load_image(image2_path)\n",
    "    return (image1, image2), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "972636bc-3f56-4dd4-b9ea-92579882859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths_1 = [f\"dataset/ref_{i}_right.png\" for i in range(1, 501) for _ in range(2)]\n",
    "image_paths_2 = [f\"dataset/ref_{i}_{either}.png\" for i in range(1, 501) for either in [\"right\", \"wrong\"]]\n",
    "labels = [j for _ in range(1, 501) for j in range(1, -1, -1)]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((image_paths_1, image_paths_2, labels))\n",
    "train_dataset = train_dataset.map(load_pairs).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423bb824-c2aa-4ecd-98bd-3855e43e75bd",
   "metadata": {},
   "source": [
    "# Training\n",
    "`siamese_model.h5` clocks in at ~285 MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeb30e27-fac7-4067-a275-6fbdd3263a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 16s 422ms/step - loss: 0.4077 - accuracy: 0.8910\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 12s 370ms/step - loss: 0.3329 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 12s 369ms/step - loss: 0.3213 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 12s 370ms/step - loss: 0.2979 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 12s 369ms/step - loss: 0.2412 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 12s 370ms/step - loss: 0.1508 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 12s 369ms/step - loss: 0.0693 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 12s 368ms/step - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 12s 369ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 12s 369ms/step - loss: 0.0086 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/intel/oneapi/intelpython/envs/tensorflow-gpu/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "comparison_model.fit(train_dataset, epochs=10)\n",
    "comparison_model.save('siamese_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1433f4-7f91-47db-8c09-f09858a8340f",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9df6da7c-fb5b-4bf4-85c6-9ebb1b31e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 211ms/step\n",
      "Prediction: [[0.9223337]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('siamese.h5')\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(400, 400))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "image1_path = \"test_right_3.png\"\n",
    "image2_path = \"test_wrong_3.png\"\n",
    "\n",
    "image1 = preprocess_image(image1_path)\n",
    "image2 = preprocess_image(image2_path)\n",
    "\n",
    "input_pair = [image1, image2]\n",
    "\n",
    "prediction = model.predict(input_pair)\n",
    "print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd3732-9b3a-4bc5-9212-cc44f16affe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow GPU",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

================
File: model/train.py
================
import numpy as np
import tensorflow as tf
# tensorflow.keras loaded lazily - ide may give resolution errors
from tensorflow.keras.applications import VGG16
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import preprocess_input
from scipy.spatial import distance

vgg_model = VGG16(weights="imagenet", include_top=False, input_shape=(400, 400, 3))

vgg_model.summary()

def load_and_preprocess_image(image_path):
    img = image.load_img(image_path, target_size=(400, 400))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)  # add batch dimension
    img_array = preprocess_input(img_array)
    return img_array

image_1 = load_and_preprocess_image("/Users/albonwu/Documents/College/F24/mhacks-17/model/dataset/reference1_cropped.png")
image_2 = load_and_preprocess_image("/Users/albonwu/Documents/College/F24/mhacks-17/model/dataset/reference3_cropped.png")

features_image_1 = vgg_model.predict(image_1)
features_image_2 = vgg_model.predict(image_2)

features_image_1_flat = features_image_1.flatten()
features_image_2_flat = features_image_2.flatten()

# compute euclidean distance
euclidean = np.linalg.norm(features_image_1_flat - features_image_2_flat)
cosine = 1 - distance.cosine(features_image_1_flat, features_image_2_flat)

print("euclidean distance", euclidean)
print("cosine similarity", cosine)

================
File: .babelrc
================
{
  "presets": ["next/babel"],
  "plugins": []
}

================
File: README.md
================
<h1 align="center">
<a href="https://devpost.com/software/cascade-xrfscu">Cascade</a>
</h1>

<p align="center">An elegant, functional CSS trainer.</p>

## Inspiration
When your CSS gets rusty, you don’t want to have to start a new project to get back in shape. You want to review **key syntax elements** and recover your muscle memory as frictionlessly as possible.

## What it does
Cascade provides a sleek, efficient interface for practicing CSS. It displays a series of intelligently-rendered styled component similar to ones you might see in real development, and your job is to recreate them as quickly as possible.

## How we built it
The backend, deployed on Heroku, uses Flask and MongoDB. It stores a history of puzzles per session and generates images for each puzzle from raw HTML/CSS. The ruleset generation is handled by a Breadboard project that leverages Gemini-based agents.

The grading system uses a Siamese neural network trained in the Intel Tiber Developer Cloud. It jointly utilizes two pretrained VGG16 CNNs and some final comparison layers manually trained using the Intel Max Series GPU on 4th Gen Intel Xeon processors. It is hosted in an ITDC instance running the same hardware, and deployed using ngrok.

The frontend is built on Next.js, which provides a robust interface for the application. 

## Challenges we ran into
We had to make our own buildpack for Heroku, so deploying and installing binaries for the project was particularly difficult. An inherent challenge of our project was implementing a live preview of HTML without introducing security issues - we identified the proper dependencies to do so. 

## Accomplishments that we're proud of
Our process of generating training data for the Siamese neural network, as well as training it, is highly optimized for time and space efficiency. We generated over a gigabyte of training data within minutes, and by freezing key layers in the network, we managed to reduce training time over tenfold without sacrificing performance.

## What's next for Cascade
More validation, testing, and expansion to multiple users.
